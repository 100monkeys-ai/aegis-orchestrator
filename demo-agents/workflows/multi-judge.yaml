apiVersion: 100monkeys.ai/v1
kind: Workflow

metadata:
  name: "multi-judge-test"
  version: "1.0.0"
  description: "Test multi-judge consensus"

spec:
  context:
    test_code: |
      def add(a, b):
          return a + b
      
      print(add(2, 3))

  initial_state: VALIDATE_WITH_PANEL

  states:
    VALIDATE_WITH_PANEL:
      kind: ParallelAgents
      agents:
        - agent: "basic-judge"
          input: "Evaluate this code for correctness: {{workflow.context.test_code}}"
          weight: 1.0
        
        - agent: "basic-judge"
          input: "Evaluate this code for style: {{workflow.context.test_code}}"
          weight: 0.5
        
        - agent: "basic-judge"
          input: "Evaluate this code for security: {{workflow.context.test_code}}"
          weight: 1.5

      consensus:
        strategy: weighted_average
        threshold: 0.7

      timeout: 120s

      transitions:
        - condition: consensus
          threshold: 0.7
          min_agreement: 0.6
          target: APPROVED

        - condition: any_rejected
          target: REJECTED

    APPROVED:
      kind: System
      command: "echo"
      env:
        MESSAGE: "Code approved by consensus"
        FINAL_SCORE: "{{VALIDATE_WITH_PANEL.final_score}}"
      transitions: []

    REJECTED:
      kind: System
      command: "echo"
      env:
        MESSAGE: "Code rejected by consensus"
      transitions: []